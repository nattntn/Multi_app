import streamlit as st
from PIL import Image
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.preprocessing.image import img_to_array


import sys
sys.path.append('./efficientnet_keras_transfer_learning')

# model
from efficientnet.layers import Swish, DropConnect
from efficientnet.model import ConvKernalInitializer
from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras.models import load_model


get_custom_objects().update({
    'ConvKernalInitializer': ConvKernalInitializer,
    'Swish': Swish,
    'DropConnect':DropConnect
})

model = load_model('../Multi_app/data/16_Multi_8e-6_250_Unfreeze.h5') #paper
#-------------------------------------------------------------------
# cut_image.py
def cut_image(image):
    width, height = image.size
    frac=0.6
    crop_left_width = int(width * frac)
    cropped_left = image.crop((0, 0, crop_left_width, height))
    crop_right_width = width - crop_left_width
    cropped_right = image.crop((crop_right_width, 0, width, height)).transpose(Image.FLIP_LEFT_RIGHT)
    return cropped_left, cropped_right
#---------------------------------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
#def predict_image(img_path,model, height, width):
    # Read the image and resize it
    #img = image.load_img(img_path, target_size=(height, width))
    # Convert it to a Numpy array with target shape.
    #x = image.img_to_array(img)
    # Reshape
    #x = x.reshape((1,) + x.shape)
    #x /= 255.
    #result = model.predict([x])
    #return result

def predict_image(img, model, height, width):
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏£‡∏¢‡πå
    img = img.resize((height, width))  # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û
    x = img_to_array(img) / 255.0  # Normalize ‡∏†‡∏≤‡∏û
    x = np.expand_dims(x, axis=0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥ batch
    result = model.predict(x)
    return result
#----------------------------------------------------------------------------------
#‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ confident
def calculate_confident(value):
    if value >= 0.5: #male
        confident = value
    else:
        confident = 1 - value #female
    return confident

#----------------------------------------------------------------------------------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏®
def predict_age_gender(img_paths):
    pred_list_regression = []
    pred_list_classification = []

    for img in img_paths:
        height = width = model.input_shape[1]
        predictions = predict_image(img, model, height, width)
        regression_result = predictions[0]
        classification_result = predictions[1]
        pred_list_regression.append(regression_result)
        pred_list_classification.append(classification_result)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à
    con_0 = calculate_confident(pred_list_classification[0][0][0])
    con_1 = calculate_confident(pred_list_classification[1][0][0])
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    if con_0 > con_1:
        gender_pred = "Male" if pred_list_classification[0][0][0] >= 0.5 else "Female"
        age_pred = np.around(pred_list_regression[0][0][0])
    else:
        gender_pred = "Male" if pred_list_classification[1][0][0] >= 0.5 else "Female"
        age_pred = np.around(pred_list_regression[1][0][0])

    confidence = max(con_0, con_1)
    return age_pred, gender_pred, confidence

#--------------------------------------------------------------------------------------
# ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ
import os
if not os.path.exists("uploads"):
    os.makedirs("uploads")
#-------------------------------------------------------------------------------------

# UI
st.markdown("<h1 style='text-align: center;'> ü¶∑ Age and Sex Estimation via Panoramic X-ray Image</h1>", unsafe_allow_html=True)
st.write("") 
st.write("") 

# ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
uploaded_file = st.file_uploader("Choose a dental X-ray image", type=["jpg", "jpeg", "png"])


if uploaded_file is not None:
    image = Image.open(uploaded_file)
    filename = uploaded_file.name  # Get the filename
    st.image(image, caption=f"Uploaded X-ray image: {filename}", use_column_width=True)

   # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏•‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå "uploads"
    image_path = os.path.join("uploads", filename)
    image.save(image_path)

    # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏ã‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ç‡∏ß‡∏≤
    left_img, right_img = cut_image(image)
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏¢‡∏∏‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏®‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á
    age, gender, confidence = predict_age_gender([left_img, right_img])

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    st.subheader("Prediction Results")
    st.write(f"<span style='font-size:24px;'> <b>Age</b>: <span style='color:green;'><b>{int(age)}</b></span> </span><span style='font-size:20px;'>years </span>", unsafe_allow_html=True)
    st.write(f"<span style='font-size:24px;'> <b>Sex</b>: <span style='color:green;'><b>{gender}</b></span> </span><span style='font-size:20px;'>(Confidence: <span style='color:blue;'>{confidence*100:.2f}%)</span> </span>", unsafe_allow_html=True)
